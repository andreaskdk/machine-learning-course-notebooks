{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GeneratingPokemonNamesLSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"fJDEXDnGppUg","colab_type":"text"},"source":["# Generating Pokemon Names\n","\n","![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/International_Pok%C3%A9mon_logo.svg/640px-International_Pok%C3%A9mon_logo.svg.png)\n","\n","In this exercise we will train a recurrent neural network that can generate names of Pokemons. We can retrieve data on Pokemons from the [Pokemon API](https://pokeapi.co/).\n","\n","\n","First, we will fetch the list of Pokemon names from the pokeapi. The names need a bit of preprocessing and deduplication. We will also add a **\".\"** to the end of each name. This will be an indication of the end of the name once we have a model that can generate new Pokemon names for us. "]},{"cell_type":"code","metadata":{"id":"i97omIqdpgbA","colab_type":"code","outputId":"0ce1851f-ef53-4787-c662-e3b3c503188d","executionInfo":{"status":"ok","timestamp":1567167071909,"user_tz":-120,"elapsed":3945,"user":{"displayName":"Andreas Koch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBkfYvmKImRK_RvnjRpMRNl4Vh2LXoQUUdMILaetg=s64","userId":"13896205142185313086"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"source":["%tensorflow_version 2.x\n","\n","import numpy as np\n","import requests\n","import tensorflow as tf\n","\n","result = requests.get(\"https://pokeapi.co/api/v2/pokemon/?limit=1000\").json()\n","names = list(set([result['results'][i]['name'].split(\"-\")[0]+\".\" for i in range(result['count'])]))\n","\n","names[:20]"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['dunsparce.',\n"," 'beheeyem.',\n"," 'krabby.',\n"," 'granbull.',\n"," 'milotic.',\n"," 'sneasel.',\n"," 'hippopotas.',\n"," 'oricorio.',\n"," 'komala.',\n"," 'gumshoos.',\n"," 'bulbasaur.',\n"," 'maractus.',\n"," 'piloswine.',\n"," 'rhyhorn.',\n"," 'togetic.',\n"," 'solosis.',\n"," 'octillery.',\n"," 'toxicroak.',\n"," 'lotad.',\n"," 'tornadus.']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"bvrDJARZBart","colab_type":"text"},"source":["We will generate the names character by character, so first we need to identify all the unique characters used in the Pokemon names."]},{"cell_type":"code","metadata":{"id":"UL_rjNe5sqaR","colab_type":"code","colab":{}},"source":["chars = set()\n","\n","chars.update(\"\".join(names))\n","char_to_index = dict(zip(chars, range(len(chars))))\n","index_to_char = {i: c for c, i in char_to_index.items()}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ne-QQT7QFRI3","colab_type":"text"},"source":["The two dictionaries **char_to_index** and **index_to_char** will be useful for one-hot-encoding the data.\n","\n","We will now create the training data, which will have dimensions (number_of_names, maximum_length_of_name, size_of_alphabet). We will create both a tensor of features **X** and a tensor of targets **Y**. "]},{"cell_type":"code","metadata":{"id":"51HE09yQp7o-","colab_type":"code","colab":{}},"source":["max_name_length = len(max(names, key=len))\n","m = len(names)\n","char_dim = len(char_to_index)\n","\n","X = np.zeros((m, max_name_length, char_dim))\n","Y = np.zeros((m, max_name_length, char_dim))\n","\n","for i in range(m):\n","    name = list(names[i])\n","    for j in range(len(name)):\n","        X[i, j, char_to_index[name[j]]] = 1\n","        if j < len(name)-1:\n","            Y[i, j, char_to_index[name[j+1]]] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pAGeme02ScA0","colab_type":"text"},"source":["The model will have a LSTM layer and a dense softmax layer on top. Per default the LSTM layer would only return the state at the end of each name, but since we want every character in the name to count we can specify this with **return_sequences=True**."]},{"cell_type":"code","metadata":{"id":"p8jQQb38q5s8","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.callbacks import LambdaCallback\n","\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(max_name_length, char_dim), return_sequences=True))\n","model.add(Dense(char_dim, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h0tBCGoSTDDv","colab_type":"text"},"source":["To be able to actually generate names with the model we will write a function that samples one character at a time until either a \".\" is sampled or we reach the maximum length of Pokemon names."]},{"cell_type":"code","metadata":{"id":"kkIVu-MZtJzo","colab_type":"code","colab":{}},"source":["def generate_name(model):\n","    name = []\n","    x = np.zeros((1, max_name_length, char_dim))\n","    end = False\n","    i = 0\n","    \n","    while end==False:\n","        probs = list(model.predict(x)[0,i])\n","        probs = probs / np.sum(probs)\n","        index = np.random.choice(range(char_dim), p=probs)\n","        if i == max_name_length-2:\n","            character = '.'\n","            end = True\n","        else:\n","            character = index_to_char[index]\n","        name.append(character)\n","        x[0, i+1, index] = 1\n","        i += 1\n","        if character == '.':\n","            end = True\n","    \n","    print(''.join(name))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OqPE6JIbTqqL","colab_type":"text"},"source":["In order to follow how our model is developing we use a callback function and generate three random names for every 25 epochs. Hopefully, we should see that the names are becomming more realistic as the model is trained.\n","\n","Remember: If you run the training loop again, the model will start off with the trained weights unless you recompile the model again."]},{"cell_type":"code","metadata":{"id":"lsY0sQBmtQkE","colab_type":"code","outputId":"75cdec27-fe64-44e1-ef5e-4d41e89deb52","executionInfo":{"status":"ok","timestamp":1567167148841,"user_tz":-120,"elapsed":47918,"user":{"displayName":"Andreas Koch","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBkfYvmKImRK_RvnjRpMRNl4Vh2LXoQUUdMILaetg=s64","userId":"13896205142185313086"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def generate_name_loop(epoch, _):\n","  \n","  if epoch%25 == 0:\n","    print('Name generated after epoch %d:' % epoch)\n","    for i in range(3):\n","      generate_name(model)\n","    print()\n","      \n","name_generator = LambdaCallback(on_epoch_end = generate_name_loop)\n","\n","model.fit(X, Y, batch_size=64, epochs=300, callbacks=[name_generator], verbose=0)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-2.0.0-rc0/python3.6/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Name generated after epoch 0:\n","zsupktyypjk.\n","2nlybef.\n","ubsvtjeaxbh.\n","\n","Name generated after epoch 25:\n","uugdtbn.\n","bowyula.\n","xegddeur.\n","\n","Name generated after epoch 50:\n",".\n","urodel.\n","ochedore.\n","\n","Name generated after epoch 75:\n","eelattril.\n","ollitrone.\n",".\n","\n","Name generated after epoch 100:\n","panaurr.\n","rongra.\n","wingoru.\n","\n","Name generated after epoch 125:\n","mabraa.\n","indien.\n","ogufbunf.\n","\n","Name generated after epoch 150:\n","agneogst.\n","uctron.\n","klitk.\n","\n","Name generated after epoch 175:\n","ixer.\n","oman.\n","nichoon.\n","\n","Name generated after epoch 200:\n","licoun.\n","actuffe.\n","ascung.\n","\n","Name generated after epoch 225:\n","lidocio.\n","ochoynn.\n","antige.\n","\n","Name generated after epoch 250:\n","udbray.\n","rofelta.\n","olitraka.\n","\n","Name generated after epoch 275:\n","lickily.\n","irlion.\n","esceviar.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fedf111dcc0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"K9DpWRnhT_JB","colab_type":"text"},"source":["Do you think that the model is good?\n","\n","Can you tell the generated Pokemon names from real ones?\n","\n","What else do you think can be successfully generated with RNNs?"]},{"cell_type":"code","metadata":{"id":"q9eY5H9qU1rR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}