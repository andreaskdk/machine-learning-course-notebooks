{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InformationLeakage.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JCS7jwnSbdg5","colab_type":"text"},"source":["# Information Leakage\n","\n","In this notebook we will explore how information can leak from the training data to the test data. For the example we will create a dummy dataset.\n"]},{"cell_type":"code","metadata":{"id":"YD_DBVfvgqx_","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bazqKfvUeAfv","colab_type":"text"},"source":["We will create a dataset with 500 rows and 10000 feature columns. All features will be randomly generated values between 0 and 1. The targets will be one of two randomly chosen categories."]},{"cell_type":"code","metadata":{"id":"Qm7Qt0BNhL4H","colab_type":"code","colab":{}},"source":["X = np.random.randn(500, 10000)\n","y = np.random.choice(2, size=500)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NMSg_GdQeldn","colab_type":"text"},"source":["We will select the *best* 25 features to base our model on. Scikit-learn has a build in function to find the columns most correlated with the targets. "]},{"cell_type":"code","metadata":{"id":"M-83AX7whdCA","colab_type":"code","colab":{}},"source":["X_best = SelectKBest(k=25).fit_transform(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Jig3pUJf0hK","colab_type":"text"},"source":["As usual we split the data into a train and test set."]},{"cell_type":"code","metadata":{"id":"vLDMDV_5pgjf","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(X_best, y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gV9vOIPHbjrX","colab_type":"text"},"source":["## Stop and think!\n","\n","If we train a model with **X_train** and **y_train**, how well do you expect this model to perform on the test set?\n","\n","Once you have thought about this question, you can see if the result is as expected."]},{"cell_type":"code","metadata":{"id":"83WwuDOKpvBt","colab_type":"code","colab":{}},"source":["model = LogisticRegression(solver='lbfgs', max_iter=1000).fit(X_train, y_train)\n","performance = (model.predict(X_test) == y_test).mean()\n","print(performance)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjOxAE_Qg0Th","colab_type":"text"},"source":["We can also with cross-validation"]},{"cell_type":"code","metadata":{"id":"TFJQd0nok0lp","colab_type":"code","colab":{}},"source":["cross_val_score(LogisticRegression(solver='lbfgs', max_iter=1000), X_best, y, cv=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oirrJq4ln2g","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}